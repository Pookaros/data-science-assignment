{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480b0021-cff5-4c1b-94a7-435d020b2d7b",
   "metadata": {},
   "source": [
    "# 1.  Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab058c28-7075-4972-b08b-35e2e89c2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width           class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "dataframe = pd.DataFrame(iris.data.features)\n",
    "dataframe[\"class\"] = pd.DataFrame(iris.data.targets)\n",
    "print(dataframe)\n",
    "\n",
    "X = iris.data.features\n",
    "y = iris.data.targets\n",
    "\n",
    "# variable information (pandas)\n",
    "iris.variables\n",
    "print(iris.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c6f4b-d11a-4f1d-b9b9-d8439edba881",
   "metadata": {},
   "source": [
    "## 1.1 Handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bde80-8810-4992-9611-27eb4c40c6c9",
   "metadata": {},
   "source": [
    "### 1.1.1 Missing value/Data Type check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830f40b2-5858-4f8d-9404-8ab85acfb827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal length  150 non-null    float64\n",
      " 1   sepal width   150 non-null    float64\n",
      " 2   petal length  150 non-null    float64\n",
      " 3   petal width   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   150 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.3+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(X.info(), y.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f996114-18d6-416a-a8c3-9daf39490e4b",
   "metadata": {},
   "source": [
    "No need for fill or drop since there are no null values. There is no need for type conversions. The only need is to hotencode the categorical data of the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43a5ba-4ec0-44be-b0d4-52c0cf810a47",
   "metadata": {},
   "source": [
    "### 1.1.2 Factorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a707af-f3a9-4d64-abdc-6f7fb638783f",
   "metadata": {},
   "source": [
    "Since it is a binay classification problem we will factorize the data and not one_hot encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6393355-f0d1-41df-b191-24298a6cdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.factorize(y[\"class\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59991fc1-43b6-44af-9d07-5701871665fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ef0c2-8463-45fc-a0f0-9a5adf512075",
   "metadata": {},
   "source": [
    "### 1.1.3 Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d412a36-1ebd-4c4c-9a31-0cca45274534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sepal length  sepal width  petal length  petal width\n",
      "mean      5.843333     3.054000      3.758667     1.198667\n",
      "std       0.828066     0.433594      1.764420     0.763161\n",
      "min       4.300000     2.000000      1.000000     0.100000\n",
      "25%       5.100000     2.800000      1.600000     0.300000\n",
      "50%       5.800000     3.000000      4.350000     1.300000\n",
      "75%       6.400000     3.300000      5.100000     1.800000\n",
      "max       7.900000     4.400000      6.900000     2.500000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = dataframe.describe().drop(\"count\")\n",
    "print(summary)\n",
    "\n",
    "summary.plot(kind=\"box\", figsize=(7, 6))\n",
    "plt.title(\"Boxplot of DataFrame Columns\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0070c-370a-4905-a577-c136cdd646dc",
   "metadata": {},
   "source": [
    "We can see that we have Left skewed distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d20ea-bf0a-4c8f-ba07-be63eec6b16f",
   "metadata": {},
   "source": [
    "# 2. Visualise the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28c08b-e6cb-4087-88f3-5d0d476ad5d7",
   "metadata": {},
   "source": [
    "## 2.1 Create a pairplot according to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d8651-ff4b-46b5-9edc-dcc068c2b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1332.5x1200 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.pairplot(data=dataframe, hue=\"class\", height=3, diag_kind=\"kde\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89b837-beb4-4353-9e87-8352dc92a350",
   "metadata": {},
   "source": [
    "## 2.2 Create BoxSplots for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f154fb-474b-4ae2-9e45-63ab4447a0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames = dataframe.select_dtypes(\"float64\").columns\n",
    "colnames\n",
    "\n",
    "for col in dataframe[colnames]:\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=dataframe, x=\"class\", y=dataframe[col])\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ea0c1-ffee-4da9-ae55-5ef4d803daef",
   "metadata": {},
   "source": [
    "# 3 Test/Train Split - Choose Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d9a62-e3f1-4609-9784-7e49b3680941",
   "metadata": {},
   "source": [
    "## 3.1 Model Performance and Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e1c6c7-a4dc-4610-8645-432ab1bfcf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "\n",
    "MODEL_FILE_NAME = \"model_log.json\"\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "def dynamicmodel(model, xtrain, ytrain, xtest, ytest, as_new=False):\n",
    "    # Generate a unique identifier for the model configuration\n",
    "    model_config = str(model.get_params())\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    if not os.path.exists(MODEL_FILE_NAME):\n",
    "        with open(MODEL_FILE_NAME, \"w\") as f:\n",
    "            json.dump({}, f)\n",
    "\n",
    "    # Load the jason file (if it does not exist it will create it)\n",
    "    with open(MODEL_FILE_NAME, \"r+\") as f:\n",
    "        model_log = json.load(f)\n",
    "\n",
    "    # Check if the model configuration has been used before\n",
    "    if (model_config not in model_log) | as_new:\n",
    "        # Model creation\n",
    "        ypred = model.predict(xtest)\n",
    "\n",
    "        # Checking the bias & variance\n",
    "        train = model.score(xtrain, ytrain)\n",
    "        test = model.score(xtest, ytest)\n",
    "\n",
    "        print(f\"Training Accuracy: {train}\\nTesting Accuracy: {test}\\n\\n\")\n",
    "\n",
    "        # Model Evaluation\n",
    "        report = classification_report(ytest, ypred)\n",
    "        print(report)\n",
    "\n",
    "        cm = confusion_matrix(ytest, ypred)\n",
    "        plot_confusion_matrix(cm)\n",
    "\n",
    "        # MCC\n",
    "        mcc = matthews_corrcoef(ytest, ypred)\n",
    "        print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "        # Determine the count of the current model configuration\n",
    "        model_count = sum(1 for key in model_log.keys() if key == model_config)\n",
    "        model_name = f\"{model.__class__.__name__}_{model_count}\"\n",
    "\n",
    "        # Create Directory for the data csv\n",
    "        create_model_data_dir(model_name, xtrain, ytrain, xtest, ytest)\n",
    "\n",
    "        # Store results in the log\n",
    "        model_log[model_config] = {\n",
    "            \"model_name\": model_name,\n",
    "            \"data_trained\": os.getcwd() + \"\\\\\" + model_name,\n",
    "            \"train_accuracy\": train,\n",
    "            \"test_accuracy\": test,\n",
    "            \"classification_report\": report,\n",
    "            \"confusion_matrix\": cm.tolist(),\n",
    "            \"mcc\": mcc,\n",
    "        }\n",
    "\n",
    "        # Write log to a file\n",
    "        with open(MODEL_FILE_NAME, \"w\") as f:\n",
    "            json.dump(model_log, f, indent=4, ensure_ascii=False)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Model with hyperparameters has been used before. And the results where:\"\n",
    "        )\n",
    "        print_model_log(model_config)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_model_log(model_config):\n",
    "    with open(MODEL_FILE_NAME, \"r\") as f:\n",
    "        model_log = json.load(f)\n",
    "\n",
    "    if model_config in model_log:\n",
    "        print(f\"Model Configuration: {model_config}\")\n",
    "        print(model_log[model_config][\"data_trained\"])\n",
    "        print(model_log[model_config][\"model_name\"])\n",
    "        print(model_log[model_config][\"train_accuracy\"])\n",
    "        print(model_log[model_config][\"test_accuracy\"])\n",
    "        print(model_log[model_config][\"classification_report\"])\n",
    "        plot_confusion_matrix(model_log[model_config][\"confusion_matrix\"])\n",
    "        print(model_log[model_config][\"mcc\"])\n",
    "    else:\n",
    "        print(f\"Model with hyperparameters {model_config} not found in the log.\")\n",
    "\n",
    "\n",
    "def create_model_data_dir(model_name, xtrain, ytrain, xtest, ytest):\n",
    "    if not os.path.exists(model_name):\n",
    "        os.makedirs(model_name)\n",
    "\n",
    "        xtrainpath = os.path.join(model_name, \"xtrain.csv\")\n",
    "        ytrainpath = os.path.join(model_name, \"ytrain.csv\")\n",
    "        xtestpath = os.path.join(model_name, \"xtest.csv\")\n",
    "        ytestpath = os.path.join(model_name, \"ytest.csv\")\n",
    "\n",
    "        xtrain_df = pd.DataFrame(xtrain)\n",
    "        ytrain_df = pd.DataFrame(ytrain)\n",
    "        xtest_df = pd.DataFrame(xtest)\n",
    "        ytest_df = pd.DataFrame(ytest)\n",
    "\n",
    "        xtrain_df.to_csv(xtrainpath, index=False)\n",
    "        ytrain_df.to_csv(ytrainpath, index=False)\n",
    "        xtest_df.to_csv(xtestpath, index=False)\n",
    "        ytest_df.to_csv(ytestpath, index=False)\n",
    "\n",
    "\n",
    "def save_to_unique_csv(df, file_name):\n",
    "    # Extract the file name and extension\n",
    "    file_name, file_extension = os.path.splitext(file_name)\n",
    "\n",
    "    # Initialize the suffix counter\n",
    "    suffix = 1\n",
    "\n",
    "    # Generate a unique file name\n",
    "    while os.path.exists(f\"{file_name}_{suffix}{file_extension}\"):\n",
    "        suffix += 1\n",
    "\n",
    "    # Save the DataFrame to the unique CSV file\n",
    "    df.to_csv(f\"{file_name}_{suffix}{file_extension}\", index=False)\n",
    "\n",
    "    return f\"{file_name}_{suffix}{file_extension}\"\n",
    "\n",
    "\n",
    "def create_unique_directory(base_dir):\n",
    "    # Initialize the suffix counter\n",
    "    suffix = 1\n",
    "\n",
    "    # Generate a unique directory name\n",
    "    while True:\n",
    "        dir_name = f\"{base_dir}_{suffix}\"\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "            return dir_name\n",
    "        suffix += 1\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75484ec6-c529-4902-9949-052178b45354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\KNeighborsClassifier_0\n",
      "KNeighborsClassifier_0\n",
      "0.9523809523809523\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.95      1.00      0.97        18\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9669271325552267\n",
      "Model: LogisticRegression\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\LogisticRegression_0\n",
      "LogisticRegression_0\n",
      "0.9809523809523809\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671684881739483\n",
      "Model: SVC\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\SVC_0\n",
      "SVC_0\n",
      "0.9619047619047619\n",
      "0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671684881739483\n",
      "Model: DecisionTreeClassifier\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\DecisionTreeClassifier_0\n",
      "DecisionTreeClassifier_0\n",
      "1.0\n",
      "0.9555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9326347305389222\n",
      "Model: SGDClassifier\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\SGDClassifier_0\n",
      "SGDClassifier_0\n",
      "0.780952380952381\n",
      "0.7111111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        14\n",
      "           1       1.00      0.28      0.43        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.71        45\n",
      "   macro avg       0.82      0.76      0.70        45\n",
      "weighted avg       0.84      0.71      0.67        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6549351054537496\n"
     ]
    }
   ],
   "source": [
    "knn = dynamicmodel(KNeighborsClassifier(), xtrain, ytrain, xtest, ytest)\n",
    "logreg = dynamicmodel(LogisticRegression(), xtrain, ytrain, xtest, ytest)\n",
    "svm = dynamicmodel(SVC(), xtrain, ytrain, xtest, ytest)\n",
    "dt = dynamicmodel(DecisionTreeClassifier(), xtrain, ytrain, xtest, ytest)\n",
    "sgd = dynamicmodel(SGDClassifier(), xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc92ab9-1fd7-4a26-b8ac-4636343e3d9a",
   "metadata": {},
   "source": [
    "Since the magnitudes of the features does not vary there is no need for scaling and as a result no need for a pipeline for now. Most of the models seem to have low bias and high variance.\n",
    "The most promissing seems to be the Logistic regression one. But following the literature I will go with the Stochastic Gradient Descent (SGD)\n",
    "and do some hyperparameter tuning to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc893e-d444-4425-a33d-cd1bd9d59925",
   "metadata": {},
   "source": [
    "## 3.2 Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cd40f1-d245-4355-a252-cb867a9aae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2160 candidates, totalling 10800 fits\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0001, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0002, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0003, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0004, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=log_loss, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=modified_huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_hinge, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=perceptron, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=500, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=1000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l2; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=l1; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=elasticnet; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n",
      "[CV] END alpha=0.0005, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=2000, penalty=None; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "8100 fits failed out of a total of 10800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 905, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 153, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ \\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SGDClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;modified_huber&#x27;,\n",
       "                                  &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;,\n",
       "                                  &#x27;squared_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;epsilon_insensitive&#x27;,\n",
       "                                  &#x27;squared_epsilon_insensitive&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [500, 1000, 2000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SGDClassifier(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
       "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;optimal&#x27;, &#x27;invscaling&#x27;,\n",
       "                                           &#x27;adaptive&#x27;],\n",
       "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;modified_huber&#x27;,\n",
       "                                  &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;,\n",
       "                                  &#x27;squared_error&#x27;, &#x27;huber&#x27;,\n",
       "                                  &#x27;epsilon_insensitive&#x27;,\n",
       "                                  &#x27;squared_epsilon_insensitive&#x27;],\n",
       "                         &#x27;max_iter&#x27;: [500, 1000, 2000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SGDClassifier(),\n",
       "             param_grid={'alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
       "                         'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                  'squared_hinge', 'perceptron',\n",
       "                                  'squared_error', 'huber',\n",
       "                                  'epsilon_insensitive',\n",
       "                                  'squared_epsilon_insensitive'],\n",
       "                         'max_iter': [500, 1000, 2000],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet', None]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"loss\": [\n",
    "        \"hinge\",\n",
    "        \"log_loss\",\n",
    "        \"modified_huber\",\n",
    "        \"squared_hinge\",\n",
    "        \"perceptron\",\n",
    "        \"squared_error\",\n",
    "        \"huber\",\n",
    "        \"epsilon_insensitive\",\n",
    "        \"squared_epsilon_insensitive\",\n",
    "    ],\n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None],\n",
    "    \"alpha\": [i / 10000 for i in range(1, 6)],\n",
    "    \"max_iter\": [500, 1000, 2000],\n",
    "    \"learning_rate\": [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(SGDClassifier(), parameters, verbose=2)\n",
    "grid.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7585614-9712-4241-86e8-6ad29c5d4061",
   "metadata": {},
   "source": [
    "## 3.3 Decide best Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e99b4bd-af05-49fa-b5b7-b0f0199d43ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961904761904762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4450a867-9e98-42ac-a017-b3a0d4dc8d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=0.0004, loss=&#x27;squared_hinge&#x27;, penalty=&#x27;l1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.0004, loss=&#x27;squared_hinge&#x27;, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=0.0004, loss='squared_hinge', penalty='l1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0178d0b-3e4f-4ede-b10a-1b8d30514716",
   "metadata": {},
   "source": [
    "We can notice that even with tuning the SGD Classifier does not perform as well as the Logistic Regression. So we will go on with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b2970-df8c-4b75-810f-bbfe75fa818b",
   "metadata": {},
   "source": [
    "# 4 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe55f4f-1e8e-42b8-995d-cabe830d9552",
   "metadata": {},
   "source": [
    "## Classification report (Accuracy/Precision/Recall/F1 - Confusion Matrix - MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80421d93-8941-44ed-9196-b85a066511fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SGDClassifier\n",
      "Model with hyperparameters has been used before. And the results where:\n",
      "Model Configuration: {'alpha': 0.0003, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "C:\\Users\\ \\Desktop\\python\\FinartixAssignement\\SGDClassifier_0\n",
      "SGDClassifier_0\n",
      "0.9047619047619048\n",
      "0.8222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        14\n",
      "           1       1.00      0.56      0.71        18\n",
      "           2       0.68      1.00      0.81        13\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.85      0.85      0.82        45\n",
      "weighted avg       0.87      0.82      0.81        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7670626808109744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=0.0003, loss=&#x27;squared_hinge&#x27;, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.0003, loss=&#x27;squared_hinge&#x27;, penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=0.0003, loss='squared_hinge', penalty=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the best estimator\n",
    "sgd = SGDClassifier(alpha=0.0003, loss=\"squared_hinge\", penalty=None)\n",
    "dynamicmodel(sgd, xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d90e94-a727-4129-9474-0db3e77c7308",
   "metadata": {},
   "source": [
    "We have a balanced trade-off between precision and recall. Although a recall of 0.77 is kinda low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d338f-2470-4e26-98ff-8372f57bc738",
   "metadata": {},
   "source": [
    "MCC of 0.9041146957369786 indicates a relatively good performance of  model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a4f6b-7a73-4150-85d3-a998f7fffcf1",
   "metadata": {},
   "source": [
    "## 4.4 Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67405467-4dcc-43c6-8359-9cf75044ad72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGDClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importances in SGD Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mPlotFeatureImportance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msgd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mPlotFeatureImportance\u001b[1;34m(model, x_train)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPlotFeatureImportance\u001b[39m(model, x_train):\n\u001b[1;32m----> 8\u001b[0m     feature_importances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m)\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mbarh(\u001b[38;5;28mrange\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), feature_importances[\u001b[38;5;241m0\u001b[39m], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGDClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "# Extract feature importances\n",
    "# Note: SGDClassifier doesn't have a built-in attribute to directly retrieve feature importances,\n",
    "# but we can approximate it by looking at the magnitude of the learned coefficients\n",
    "def PlotFeatureImportance(model, x_train):\n",
    "    feature_importances = np.abs(model.coef_)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(range(x_train.shape[1]), feature_importances[0], align=\"center\")\n",
    "    plt.yticks(range(x_train.shape[1]), x_train.columns)\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Feature Importances in SGD Classifier\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "PlotFeatureImportance(sgd, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e02baf-2424-422f-a14c-540159035991",
   "metadata": {},
   "source": [
    "Here we can see how important each feature is. Long story short you can make a preety good estimation just from the petal's length. Let's make a test\n",
    "by creating a simillar model only using the petal length as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35263969-5065-4fea-8925-7ec9ef28bbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SGDClassifier\n",
      "Training Accuracy: 0.8571428571428571\n",
      "Testing Accuracy: 0.7333333333333333\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.33      0.50        18\n",
      "           2       0.52      1.00      0.68        13\n",
      "\n",
      "    accuracy                           0.73        45\n",
      "   macro avg       0.84      0.78      0.73        45\n",
      "weighted avg       0.86      0.73      0.71        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.6852501104613512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=0.0003, loss=&#x27;squared_hinge&#x27;, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.0003, loss=&#x27;squared_hinge&#x27;, penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=0.0003, loss='squared_hinge', penalty=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(alpha=0.0003, loss=\"squared_hinge\", penalty=None)\n",
    "dynamicmodel(\n",
    "    sgd,\n",
    "    xtrain[\"petal length\"].values.reshape(-1, 1),\n",
    "    ytrain,\n",
    "    xtest[\"petal length\"].values.reshape(-1, 1),\n",
    "    ytest,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569f26d-5a9e-4252-8c37-7cfc99500aeb",
   "metadata": {},
   "source": [
    "So working only with petal length seems even more promissing as working with all 4 features with an sgd model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43c058f-1dd1-4354-9526-bcad14087a87",
   "metadata": {},
   "source": [
    "# 5 Fask Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbc01a-7cea-4f45-ad70-2a19b66257d1",
   "metadata": {},
   "source": [
    "Start the application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad16c8-cdd7-498b-afa0-a0e230c4aedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'FlaskApp'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'FlaskApp'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Mar/2024 21:45:00] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 21:45:00] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [25/Mar/2024 21:45:01] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 21:45:03] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:16:05] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:16:06] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:18:48] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:18:49] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:18:50] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:21:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:21:58] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:23:49] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:23:51] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:25:31] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:25:32] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:27:26] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:27:27] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:32:49] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:32:51] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:35:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:35:44] \"GET /reload_model_log HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:39:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2024 22:40:00] \"GET /reload_model_log HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Start FlaskApp.py \n",
    "%run FlaskApp.py\n",
    "\n",
    "# Start the Flask application\n",
    "app.run(debug=False)  # Adjust the parameters as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a575d8d-7dca-4024-987f-047d4a01fbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
